# 面试问题总结

[toc]
<!--toc-->

内卷环境之下,岗位的专业分工程度越来越高,综合研发能力比较强的人真的有点水土不服.表面上视野广阔一个顶两,实际上任一方向都有比较强的可替代性.

由于之前工作涉及的领域比较多,大多在项目期间的时候深入过,退出项目栈之后又容易忘,领域知识很难迁移,找工作的时候就很麻烦,一边需要复习语言细节,一边需要复习项目细节,一边需要复习理论相关内容,一边还要复习常用工具命令用法,还要刷算法题和手撕实现细节等等,短时间复习很难覆盖全面,长时间又很容易遗忘.

特别是面试问什么的都有,问八股文背诵记忆力,问API细节甚至入参是啥,简历上任何一个点都有可能是人家感兴趣的会深入问下去的.

普通面试官考察实现细节,技术大佬会试探性问技术边界,两者都很难应对,可能曾经深入了80%,过了很长时间也只能回答出10%.工作的时候非常投入,应聘时却很难体现,就非常吃亏.

然后匹配的方向也蛮难找的,螺丝钉岗有螺丝钉岗的烦恼,研发岗有研发岗的郁闷,之前的打法有点类似深度优先遍历,快速深入快速退出然后清空记忆栈,继续遍历,锻炼出了不少解决复杂问题的能力,唯独没锻炼出记忆力.

未来还是需要在专业领域方向有更多沉淀.考虑简历上更多地剪枝以提高匹配专业度和降低面试准备难度.

把曾经涉及过的相关问题做个记录,随遇而安吧.

## 小细节
- 一些平时不需要关心或者很少使用的用法
- 没测试过就没有印象的小细节

### CPP
#### 关于C++类空间大小的计算(以下以32位编译器为例|gcc)
```CPP
#include <iostream>
using namespace std;

// 空类的大小
// 所谓类的实例化就是在内存中分配一块地址,每个实例在内存中都有独一无二的地址.同样空类也会被实例化, 所以编译器会给空类隐式地添加一个字节, 这样空类实例化之后就有了独一无二的地址了. =1
class Stu1{ };

// 非空类的存储空间以包含变量的存储大小为准 =1
class Stu2{ char a; };

// 非空类,包含函数不占用存储空间
// 类的大小与它的构造函数、析构函数和其他成员函数无关, 只已它的数据成员有关 = 1
class Stu3{
public:
    ~Stu3(){};
    void fun(){};
    char a;
};

// 非空类,包含虚函数, 会因为多一个虚函数指针(vptr)指向虚函数表
// 而且会自动对齐,所以存储是4(vptr指针) + 1(char) + 3(补齐)=8
class Stu4{
public:
    virtual ~Stu4(){};
    char a;
};

// 4(vptr指针) + 4(int) + 1(char) + 3(补齐) =12
class Stu5{
public:
    virtual ~Stu5(){};
    int a;
    char b;
};

// 有虚函数的继承, 子类的存储是父类的存储+子类的存储
// 所以存储是4(vptr指针) + 1(父成员char)  + 1(char) + 2 (补齐)= 8
class Stu6 :public Stu4 {
public:
    virtual ~Stu6(){};
    char c;
};

// 存储是4(vptr指针) + 1(父成员char) + 4(int) + 1(char) + 6(补齐) =16
class Stu7 :public Stu4 {
public:
    virtual ~Stu7(){};
    int c;
    char d;
};

// 静态变量不占用实例的存储空间 = 4(int)
class Stu8{
public:
    int a;
    static int b;
};

int main(){
    std::cout <<"1:"<< sizeof(Stu1) << std::endl;//1
    std::cout <<"2:"<< sizeof(Stu2) << std::endl;//1
    std::cout <<"3:"<< sizeof(Stu3) << std::endl;//1
    std::cout <<"4:"<< sizeof(Stu4) << std::endl;//8
    std::cout <<"5:"<< sizeof(Stu5) << std::endl;//12
    std::cout <<"6:"<< sizeof(Stu6) << std::endl;//8
    std::cout <<"7:"<< sizeof(Stu7) << std::endl;//16
    std::cout <<"8:"<< sizeof(Stu8) << std::endl;//4
}
```
- 总结
    - 类大小只跟成员变量有关,空类大小=1
    - 静态变量空间不计算在实例空间内
    - 继承时的空间大小: 计算子类和父类空间,虚函数指针只有一个,补齐只需要最后补齐

#### 继承关系中虚函数及其默认值
```cpp
#include <iostream>
using namespace std;

struct A{
  virtual int fun(int a = 10){return a;};
};

struct B : public A{
  int fun(int a = 20)override{return a;};
};

struct C : public A{
  int fun(int a = 30)override{return a+a;};
};

int main(){
    B b;
    C c;
    A* a=&b;
    cout<<a->fun()<<endl;//10
    a=&c;
    cout<<a->fun()<<endl;//20
}
```

- 总结
    - 默认值在编译期就已经确定下来了,若调用时缺省参数,子类定义的默认值会被无视,然后才会调用子类方法
    - 一般来说应该避免在虚函数中使用默认值
    - 因为还有一个点是,声明时定义了默认值,实现函数的签名内不能包含默认值,否则编译报错.
    - 规范的注释方式是在子类实现有默认值的虚方法时,在形参列表内如下注释上默认值.
        ```cpp
        struct B : public A{
        int fun(int a/*=10*/)override{return a;};
        };
        ```

## 通识类

#### AI相关

- 池化层
    - 实施池化的目的
        - 降低信息冗余
        - 提升模型的尺度不变性、旋转不变性
        - 防止过拟合
    - 常见操作
        - 最大值池化
        - 均值池化
        - 随机池化
        - 中值池化
        - 组合池化(同时利用最大值与均值池化两种的优势)

#### GPU/CUDA相关

- 并行处理的类型
    - 基于任务的并行处理
        - 操作系统与进程
    - 基于数据的并行处理
        - SIMD,单指令多数据

- 常用并行模式
    - 循环并行展开
        - 图像处理算法中,沿X轴处理时内循环,沿Y轴处理时外循环.
        - 循环并行化是OpenMP的基础
    - 派生/汇集模式
        - 比如OpenMP中,用编译指令语句定义可并行区,并行区中的代码被分成N个线程,随后再汇聚成单个线程
        - MapReduce 大规模分布式并行计算框架
    - 分条/分块
        - 使用CUDA解决问题需要将问题分条分块(CUDA提高的是简单二维网格模型)
    - 分而治之

- 体系结构
    - GPU设备包括一组SM，每个SM由包括一组SP或CUDA核(并行)
    - GPU性能由SP数量，全局内存带宽，程序员利用并行架构的充分程度
    - 解决时空局部性问题-> 多级缓存:一级缓存 二级缓存 全局内存
    - 缓存一致性 保证所有处理核的内存视图一样(CPU要求，GPU不要求)
    - GPU通过PCI-E总线与CPU或其他GPU连接
    - 纹理内存和常量内存是全局内存的特殊视图,每个SM都设置独立访问它们的总线,纹理内存用于存储插值计算所需的数据,常量内存缓存只读数据.

- CUDA
    - CUDA的SPMD模型：每个线程执行的代码一样但是数据不同
    - CUDA结构类型 SIMT-单指令多线程
    - CUDA将问题分解成线程块的网格,每块包含多个线程束,块可以按任意顺序执行
    - 线程块(可以任意顺序执行,调度到SM上时执行不中断)
    - 线程束 分块的数量一般为SM的8-16倍
    - 全局内存 纹理内存 常量内存
    - `__global__` 内核函数 指示生成GPU代码
    - `__host__` 主机函数
    - `__device__` 设备函数 用于在设备上调用该设备函数
    - `__constand__` 指示常量内存
    - `__shared__` 指示共享内存
    - 调试工具 Nsight,cuda-gdb等
    - 编译器 NVCC
    ```cpp
    threadIdx 线程索引
    blockIdx 线程块索引
    blockDim.x 每个线程块启动的线程数量
    gridDim 线程网格上的线程块数量
    const unsigned int idx = (blockIdx.x*blockDim.x)+threadIdx.x
    const unsigned int idy = (blockIdx.y*blockDim.y)+threadIdx.y
    绝对线程索引
    thraad_idx=((gridDim.x*blockDim.x)*idy)+idx;
    ```

#### 网络相关
[网络协议要点及编程方法](posts/网络协议要点及编程方法.md)


## 小测验
- 线程间通信
    - 两个进程中的线程间通信方式
        - 信号量, socket, 共享内存 ,管道,共享文件
    - 一个进程中的线程间通信方式
        - 条件变量
            - `condition_variable` 配合互斥锁可以避免忙等
            - 比起普通方法bool值的轮询,通过唤醒来替代不必要的轮询
        - 信号量(PV操作)
            ```cpp
            #include <iostream>
            #include <thread>
            #include <semaphore>
            using namespace std;

            std::counting_semaphore seamp(1); // 生产者信号量
            std::counting_semaphore seams(0); // 消费者信号量
            int num(0);

            void producer_thread(){
                while (num < 10){
                    seamp.acquire(); //p
                    num += 1;
                    cout << "producer: " << num << endl;
                    seams.release(); //v
                }
            }
            void consumer_thread(){
                while (num < 10){
                    seams.acquire();
                    cout << "consumer: " << num << endl;
                    seamp.release();
                }
            }

            int main(){
                thread tp1(producer_thread);
                thread ts1(consumer_thread);
                tp1.join();
                ts1.join();
            }
            ```
        - 原子操作
            - `atomic` 可以取代mutex和lock
        - 同步原语：future and async/packaged_task/promise
            - `thread promise` 低级接口
                ```cpp
                #include <iostream>
                #include <future>
                #include <thread>
                #include <chrono>
                using namespace std;

                void thread_set_promise(std::promise<int>& pm) {
                    cout << "1";
                    this_thread::sleep_for(100ms);
                    pm.set_value(2);
                    cout << "3";
                }

                int main() {
                    promise<int> pm;
                    future<int> fu = pm.get_future();
                    thread t(&thread_set_promise, ref(pm));
                    cout << fu.get();//block
                    t.join();
                    system("pause");
                }
                //132
                ```
            - `async() future` 高级接口
                ```cpp
                #include <future>
                #include <thread>
                #include <iostream>
                #include <random>
                #include <chrono>
                using namespace std;
                int work(char c){
                    default_random_engine e(c);
                    uniform_int_distribution<int> id(10,100);
                    for(int i=0;i<10;i++){
                        this_thread::sleep_for(chrono::milliseconds(id(e)));
                        cout.put(c).flush();
                    }
                    return c;
                }
                int f1(){
                    return work('.');
                }
                int f2(){
                    return work('+');
                }
                int main(){
                    future<int> r1(async(f1));                   // async启动异步线程(不保证)
                    //future<int> r1(async(launch::async, f1));    // async启动异步线程(保证)
                    //future<int> r1(async(launch::deferred, f1)); // async启动异步线程(延迟到get)
                    auto ret = r1.wait_for(10ms);
                    switch (ret){
                        case future_status::ready:{
                            cout<<"ready";
                            r1.get()+ f2();
                            break;
                        }
                        case future_status::deferred:{
                            cout<<"deferred";
                            r1.get()+ f2();

                            break;
                        }
                        case future_status::timeout:{
                            cout<<"timeout";
                            r1.get()+ f2();
                            break;
                        }
                    }
                    system("pause");
                }
                //.+.+..+...+..++.++++ready
                //..timeout........++++++++++
                // ++++++++++deferred..........
                ```
            - `packaged_task, future`
                - `packaged_task`和`function`的区别在于前者返回值以future返回
                    ```cpp
                    #include <iostream>
                    #include <future>
                    #include <thread>
                    using namespace std;
                    int func (int x){
                        return x;
                    }
                    int main() {
                        std::packaged_task<int(int)> t(func);
                        std::thread t1(std::ref(t), 1);
                        std::future<int> fu = t.get_future();
                        std::shared_future<int> fus = fu.share();
                        cout<< fus.get();
                        system("pause");
                    }
                    ```
        - 锁
            - 互斥锁
                - `mutex & Lock_guard | unique_lock`
                - `recursive_mutex` 允许同一线程多次调用
                - `timed_mutex` 可以 `try_lock_for`等待一段时间
                - 尝试/同时锁定多个锁
                    ```cpp
                    std::lock(m1,m2);
                    std::try_lock(m1,m2);
                    // 注意需要过继给lock_guard
                    std::lock_guard<std::mutex> lg_m1(m1,std::adopt_lock);
                    std::lock_guard<std::mutex> lg_m2(m2,std::adopt_lock);
                    ```

            - 读写锁
                - 解决多线程同时读
                - 共享锁`std::shared_lock<std::shared_mutex>`
                - 独占锁`std::unique_lock<std::shared_mutex>`
                ```cpp
                #include <shared_mutex> //C++17
                #include <thread>
                #include <vector>
                #include <iostream>
                using namespace std;

                shared_mutex mu;
                vector<int> vec;
                bool is_run = 1;

                void read(){
                    while(is_run){
                        shared_lock sl(mu);
                        if(!vec.empty()){
                            cout << "read_id:" << this_thread::get_id() << " num:" << vec.front() << endl;
                            vec.erase(vec.begin());
                        }
                        sl.unlock();
                        // this_thread::sleep_for(100ms);
                    }
                }

                void write(){
                    static int num;
                    while(is_run){
                        if(vec.size()<10){
                            unique_lock ul(mu);
                            cout << "write_id:" << this_thread::get_id() << " num:" << num << endl;
                            vec.push_back(num++);
                            ul.unlock();
                        }else{
                            // this_thread::sleep_for(100ms);
                        }
                    }
                }

                int main(){
                    thread t1(write);
                    thread t2(read);
                    thread t3(read);
                    t1.detach();
                    t2.detach();
                    t3.detach();
                    this_thread::sleep_for(1s);
                    is_run = false;
                    system("pause");
                }
                ```
            - 多线程条件变量+互斥锁 生产者消费者模型
                ```cpp
                #include<iostream>
                #include<thread>
                #include<mutex>
                #include<condition_variable>
                #include<vector>

                using namespace std;

                mutex mu;
                condition_variable cv;
                vector<int> vec;
                bool is_run=true;

                void productor(){
                    static int num =1;
                    while (is_run){
                        unique_lock<mutex> ul(mu);
                        cv.wait(ul, []()
                                { return (vec.size() < 10); }); // 满10等待
                        cout << "生产者：" << this_thread::get_id() << " 生产：" << num << endl;
                        vec.push_back(num++);
                        ul.unlock(); //只需对操作共享结构加锁
                        cv.notify_all(); //通知消费者
                    }
                }

                void consumer(){
                    while(is_run){
                        unique_lock<mutex> ul(mu);
                        cv.wait(ul,[](){return (vec.size()>=1);});// 小于1等待
                        cout << "消费者："<<this_thread::get_id() <<" 消费："<<vec.front() << endl;
                        vec.erase(vec.begin());
                        ul.unlock();//只需对操作共享结构加锁
                        cv.notify_all(); //通知生产者
                    }
                }

                int main(){
                    thread t1(productor);
                    thread t2(productor);
                    thread t3(consumer);
                    thread t4(consumer);
                    t1.detach();
                    t2.detach();
                    t3.detach();
                    t4.detach();
                    this_thread::sleep_for(10s);
                    is_run=false;
                    system("pause");
                }
                ```